{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#sigmoid and its derivative\n",
    "def sigmoid(t):\n",
    "    return 1 / (1 + np.exp(-t))\n",
    "    \n",
    "def sigmoid_derivative(p):\n",
    "    return p * (1 - p)\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self,x=[[]],y=[],numLayers=2,numNodes=2,eta=0.1,maxIter=10000):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "        self.lr = eta\n",
    "        self.numLayers = numLayers\n",
    "        self.numNodes = numNodes\n",
    "        \n",
    "        self.weights = [np.random.uniform(-1,1,(self.x.shape[1],numNodes))] #create the weights from the inputs to the first layer\n",
    "        \n",
    "        for i in range(1,numLayers-1):\n",
    "            self.weights.append(np.random.uniform(-1,1,(numNodes,numNodes))) #create the random weights between internal layers\n",
    "            \n",
    "        self.weights.append(np.random.uniform(-1,1,(numNodes,1))) #create weights from final layer to output node\n",
    "#         print(self.weights[-1])\n",
    "        \n",
    "        self.outputs = np.zeros(self.y.shape)    #creates an output array of similar size to y \n",
    "        \n",
    "        self.bias = [np.ones(numNodes)] #create bias nodes to the first layer, all 1's\n",
    "        for i in range(numLayers-1):    #create bias in btwn hidden layers\n",
    "            self.bias.append(np.ones(numNodes))\n",
    "        self.bias.append(np.ones(self.y.shape))#create bias node to last layer, to output, all 1's        \n",
    "        \n",
    "        self.train(learningRate=eta,maxIterations=maxIter) \n",
    "\n",
    "    def train(self,learningRate,maxIterations):       \n",
    "        for i in range(1,maxIterations):\n",
    "            self.feedforward()\n",
    "            self.backprop()\n",
    "\n",
    "    def predict(self,x=[]):\n",
    "        test.feedforward()\n",
    "        return self.outputs\n",
    "\n",
    "\n",
    "    def feedforward(self):\n",
    "        self.layerdata = []\n",
    "        \n",
    "        #this adds in the input layer to the first hidden layer\n",
    "        self.to_first_layer = sigmoid(np.dot(self.x, self.weights[0]) + self.bias[0])\n",
    "        self.layerdata.append(self.to_first_layer) #\n",
    "        \n",
    "        #this adds from hidden layer to hidden layer\n",
    "        for i in range(1,self.numLayers-1):\n",
    "            self.layerdata.append(sigmoid(np.dot(self.layerdata[i-1], self.weights[i] + self.bias[i])))          \n",
    "            \n",
    "        #this adds from the last hidden layer to output\n",
    "#         print(self.layerdata[-1])\n",
    "#         print(self.weights[-1])\n",
    "        \n",
    "        self.to_output_layer =  sigmoid(np.dot(self.layerdata[-1], self.weights[-1]) + self.bias[-1])\n",
    "        self.layerdata.append(self.to_output_layer) \n",
    "        self.outputs = (self.to_output_layer)\n",
    "        \n",
    "#         print(self.weights[-1])\n",
    "\n",
    "\n",
    "    def backprop(self): \n",
    "\n",
    "        #error from the actual and predicted output\n",
    "        self.error = (self.y - self.layerdata[-1])\n",
    "        \n",
    "        #update the weights to output\n",
    "        self.output_layer_gradient = sigmoid_derivative(self.layerdata[-1])      \n",
    "        self.hidden_delta = self.error * self.output_layer_gradient #output delta\n",
    "        test = np.dot(self.to_first_layer.T, self.hidden_delta) * self.lr  \n",
    "        print(test)\n",
    "        print(self.weights[-1])\n",
    "        self.weights[-1] = self.weights[-1] +  np.dot(self.to_first_layer.T, self.hidden_delta) * self.lr \n",
    "        \n",
    "#         print(self.weights[-1])\n",
    "        \n",
    "        #loop the hidden layers  \n",
    "        j = -1\n",
    "        for i in range(1, self.numLayers-1,):\n",
    "            self.hidden_layer_gradient = sigmoid_derivative(self.layerdata[j-1])    \n",
    "            \n",
    "            self.hidden_error = np.dot(self.hidden_delta,self.weights[j].T) \n",
    "            self.hidden_delta = self.hidden_error * self.hidden_layer_gradient\n",
    "#             print(np.dot(self.layerdata[j-1].T, self.hidden_delta) * self.lr  )\n",
    "            self.weights[j-1] = self.weights[j-1] +  np.dot(self.layerdata[j-1].T, self.hidden_delta) * self.lr  \n",
    "            j = j-1\n",
    "            \n",
    "        #update the input's weights\n",
    "        self.hidden_layer_gradient = sigmoid_derivative(self.to_first_layer)         \n",
    "        self.hidden_error = np.dot(self.hidden_delta,self.weights[1].T)\n",
    "        self.hidden_delta = self.hidden_error * self.hidden_layer_gradient\n",
    "        self.weights[0] = self.weights[0] + np.dot(self.x.T, self.hidden_delta) * self.lr  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def setUp(self):\n",
    "        self.testOne = np.array([[0,1],[1,0],[0,0],[1,1]])\n",
    "        self.outOne = np.array([1,0,1,0])\n",
    "        \n",
    "        self.outTwo = np.array([1,1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00419145 -0.0299958   0.00419145 -0.0299958 ]\n",
      " [ 0.00297297 -0.02132222  0.00297297 -0.02132222]\n",
      " [ 0.00330912 -0.02371463  0.00330912 -0.02371463]]\n",
      "[[ 0.95724757]\n",
      " [ 0.6233663 ]\n",
      " [-0.65611797]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (4,4) and (3,3) not aligned: 4 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-ba1a12a436de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(outOne.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestOne\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutOne\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-f44083242279>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, numLayers, numNodes, eta, maxIter)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#create bias node to last layer, to output, all 1's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearningRate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxIterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxIter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearningRate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxIterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-f44083242279>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, learningRate, maxIterations)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxIterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-f44083242279>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;31m#             print(np.dot(self.hidden_delta,self.weights[j-1].T))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_delta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_error\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layer_gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;31m#             print(np.dot(self.layerdata[j-1].T, self.hidden_delta) * self.lr  )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (4,4) and (3,3) not aligned: 4 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "testOne = np.array([[0,1],[1,0],[0,0],[1,1]])\n",
    "outOne = np.array([1,0,1,0])\n",
    "\n",
    "# print(outOne.shape)\n",
    "test = NeuralNetwork(testOne, outOne, 3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def test_eval_separable2(self):\n",
    "        \"\"\"Linearly separable data 2\"\"\"\n",
    "        self.nn = NeuralNetwork(self.testOne,self.outOne,3,3)\n",
    "        val = self.nn.predict(np.array([0,1]))\n",
    "        self.assertTrue(val>.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def test_eval_xor(self):\n",
    "        \"\"\"XOR data\"\"\"\n",
    "        self.nn = NeuralNetwork(self.testOne,self.outTwo,3,3)\n",
    "        val = self.nn.predict(np.array([0,0]))\n",
    "        self.assertTrue(val<0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def test_eval_xor2(self):\n",
    "        \"\"\"XOR data2\"\"\"\n",
    "        self.nn = NeuralNetwork(self.testOne,self.outTwo,3,3)\n",
    "        val = self.nn.predict(np.array([0,1]))\n",
    "        self.assertTrue(val>0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
