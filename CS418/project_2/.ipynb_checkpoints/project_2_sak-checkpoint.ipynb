{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demographics = pd.read_csv('/Users/sakina/Desktop/project_02/demographics_test.csv')\n",
    "# merged_train = pd.read_csv('/Users/sakina/Desktop/project_02/merged_train.csv')\n",
    "\n",
    "demographics = pd.read_csv('demographics_test.csv')\n",
    "merged_train = pd.read_csv('merged_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Percent White, not Hispanic or Latino</th>\n",
       "      <th>Percent Black, not Hispanic or Latino</th>\n",
       "      <th>Percent Hispanic or Latino</th>\n",
       "      <th>Percent Foreign Born</th>\n",
       "      <th>Percent Female</th>\n",
       "      <th>Percent Age 29 and Under</th>\n",
       "      <th>Percent Age 65 and Older</th>\n",
       "      <th>Median Household Income</th>\n",
       "      <th>Percent Unemployed</th>\n",
       "      <th>Percent Less than High School Degree</th>\n",
       "      <th>Percent Less than Bachelor's Degree</th>\n",
       "      <th>Percent Rural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NV</td>\n",
       "      <td>eureka</td>\n",
       "      <td>32011</td>\n",
       "      <td>1730</td>\n",
       "      <td>98.265896</td>\n",
       "      <td>0.057803</td>\n",
       "      <td>0.462428</td>\n",
       "      <td>0.346821</td>\n",
       "      <td>51.156069</td>\n",
       "      <td>27.109827</td>\n",
       "      <td>15.606936</td>\n",
       "      <td>70000</td>\n",
       "      <td>3.755365</td>\n",
       "      <td>8.415466</td>\n",
       "      <td>83.396513</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TX</td>\n",
       "      <td>zavala</td>\n",
       "      <td>48507</td>\n",
       "      <td>12107</td>\n",
       "      <td>5.798299</td>\n",
       "      <td>0.594697</td>\n",
       "      <td>93.326175</td>\n",
       "      <td>9.193029</td>\n",
       "      <td>49.723301</td>\n",
       "      <td>49.302057</td>\n",
       "      <td>12.480383</td>\n",
       "      <td>26639</td>\n",
       "      <td>11.955168</td>\n",
       "      <td>40.840797</td>\n",
       "      <td>90.869691</td>\n",
       "      <td>38.032029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VA</td>\n",
       "      <td>king george</td>\n",
       "      <td>51099</td>\n",
       "      <td>25260</td>\n",
       "      <td>73.804434</td>\n",
       "      <td>16.722090</td>\n",
       "      <td>4.441805</td>\n",
       "      <td>2.505938</td>\n",
       "      <td>50.166271</td>\n",
       "      <td>40.186065</td>\n",
       "      <td>11.868567</td>\n",
       "      <td>84342</td>\n",
       "      <td>6.479939</td>\n",
       "      <td>7.152824</td>\n",
       "      <td>65.540254</td>\n",
       "      <td>73.189450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>hamilton</td>\n",
       "      <td>39061</td>\n",
       "      <td>805965</td>\n",
       "      <td>66.354867</td>\n",
       "      <td>25.654340</td>\n",
       "      <td>2.890944</td>\n",
       "      <td>5.086945</td>\n",
       "      <td>51.870615</td>\n",
       "      <td>40.779686</td>\n",
       "      <td>14.161657</td>\n",
       "      <td>50399</td>\n",
       "      <td>7.864630</td>\n",
       "      <td>9.873275</td>\n",
       "      <td>64.404446</td>\n",
       "      <td>2.231877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TX</td>\n",
       "      <td>austin</td>\n",
       "      <td>48015</td>\n",
       "      <td>29107</td>\n",
       "      <td>63.809393</td>\n",
       "      <td>8.479060</td>\n",
       "      <td>25.502456</td>\n",
       "      <td>9.946061</td>\n",
       "      <td>50.671660</td>\n",
       "      <td>37.351840</td>\n",
       "      <td>17.799842</td>\n",
       "      <td>56681</td>\n",
       "      <td>5.782337</td>\n",
       "      <td>17.579456</td>\n",
       "      <td>79.008391</td>\n",
       "      <td>66.344090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State       County   FIPS  Total Population  \\\n",
       "0    NV       eureka  32011              1730   \n",
       "1    TX       zavala  48507             12107   \n",
       "2    VA  king george  51099             25260   \n",
       "3    OH     hamilton  39061            805965   \n",
       "4    TX       austin  48015             29107   \n",
       "\n",
       "   Percent White, not Hispanic or Latino  \\\n",
       "0                              98.265896   \n",
       "1                               5.798299   \n",
       "2                              73.804434   \n",
       "3                              66.354867   \n",
       "4                              63.809393   \n",
       "\n",
       "   Percent Black, not Hispanic or Latino  Percent Hispanic or Latino  \\\n",
       "0                               0.057803                    0.462428   \n",
       "1                               0.594697                   93.326175   \n",
       "2                              16.722090                    4.441805   \n",
       "3                              25.654340                    2.890944   \n",
       "4                               8.479060                   25.502456   \n",
       "\n",
       "   Percent Foreign Born  Percent Female  Percent Age 29 and Under  \\\n",
       "0              0.346821       51.156069                 27.109827   \n",
       "1              9.193029       49.723301                 49.302057   \n",
       "2              2.505938       50.166271                 40.186065   \n",
       "3              5.086945       51.870615                 40.779686   \n",
       "4              9.946061       50.671660                 37.351840   \n",
       "\n",
       "   Percent Age 65 and Older  Median Household Income  Percent Unemployed  \\\n",
       "0                 15.606936                    70000            3.755365   \n",
       "1                 12.480383                    26639           11.955168   \n",
       "2                 11.868567                    84342            6.479939   \n",
       "3                 14.161657                    50399            7.864630   \n",
       "4                 17.799842                    56681            5.782337   \n",
       "\n",
       "   Percent Less than High School Degree  Percent Less than Bachelor's Degree  \\\n",
       "0                              8.415466                            83.396513   \n",
       "1                             40.840797                            90.869691   \n",
       "2                              7.152824                            65.540254   \n",
       "3                              9.873275                            64.404446   \n",
       "4                             17.579456                            79.008391   \n",
       "\n",
       "   Percent Rural  \n",
       "0     100.000000  \n",
       "1      38.032029  \n",
       "2      73.189450  \n",
       "3       2.231877  \n",
       "4      66.344090  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Percent White, not Hispanic or Latino</th>\n",
       "      <th>Percent Black, not Hispanic or Latino</th>\n",
       "      <th>Percent Hispanic or Latino</th>\n",
       "      <th>Percent Foreign Born</th>\n",
       "      <th>Percent Female</th>\n",
       "      <th>Percent Age 29 and Under</th>\n",
       "      <th>Percent Age 65 and Older</th>\n",
       "      <th>Median Household Income</th>\n",
       "      <th>Percent Unemployed</th>\n",
       "      <th>Percent Less than High School Degree</th>\n",
       "      <th>Percent Less than Bachelor's Degree</th>\n",
       "      <th>Percent Rural</th>\n",
       "      <th>Democratic</th>\n",
       "      <th>Republican</th>\n",
       "      <th>Party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AZ</td>\n",
       "      <td>apache</td>\n",
       "      <td>4001</td>\n",
       "      <td>72346</td>\n",
       "      <td>18.571863</td>\n",
       "      <td>0.486551</td>\n",
       "      <td>5.947806</td>\n",
       "      <td>1.719515</td>\n",
       "      <td>50.598513</td>\n",
       "      <td>45.854643</td>\n",
       "      <td>13.322091</td>\n",
       "      <td>32460</td>\n",
       "      <td>15.807433</td>\n",
       "      <td>21.758252</td>\n",
       "      <td>88.941063</td>\n",
       "      <td>74.061076</td>\n",
       "      <td>16298</td>\n",
       "      <td>7810</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZ</td>\n",
       "      <td>cochise</td>\n",
       "      <td>4003</td>\n",
       "      <td>128177</td>\n",
       "      <td>56.299492</td>\n",
       "      <td>3.714395</td>\n",
       "      <td>34.403208</td>\n",
       "      <td>11.458374</td>\n",
       "      <td>49.069646</td>\n",
       "      <td>37.902276</td>\n",
       "      <td>19.756275</td>\n",
       "      <td>45383</td>\n",
       "      <td>8.567108</td>\n",
       "      <td>13.409171</td>\n",
       "      <td>76.837055</td>\n",
       "      <td>36.301067</td>\n",
       "      <td>17383</td>\n",
       "      <td>26929</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>coconino</td>\n",
       "      <td>4005</td>\n",
       "      <td>138064</td>\n",
       "      <td>54.619597</td>\n",
       "      <td>1.342855</td>\n",
       "      <td>13.711033</td>\n",
       "      <td>4.825298</td>\n",
       "      <td>50.581614</td>\n",
       "      <td>48.946141</td>\n",
       "      <td>10.873943</td>\n",
       "      <td>51106</td>\n",
       "      <td>8.238305</td>\n",
       "      <td>11.085381</td>\n",
       "      <td>65.791439</td>\n",
       "      <td>31.466066</td>\n",
       "      <td>34240</td>\n",
       "      <td>19249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AZ</td>\n",
       "      <td>gila</td>\n",
       "      <td>4007</td>\n",
       "      <td>53179</td>\n",
       "      <td>63.222325</td>\n",
       "      <td>0.552850</td>\n",
       "      <td>18.548675</td>\n",
       "      <td>4.249798</td>\n",
       "      <td>50.296170</td>\n",
       "      <td>32.238290</td>\n",
       "      <td>26.397638</td>\n",
       "      <td>40593</td>\n",
       "      <td>12.129932</td>\n",
       "      <td>15.729958</td>\n",
       "      <td>82.262624</td>\n",
       "      <td>41.062000</td>\n",
       "      <td>7643</td>\n",
       "      <td>12180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AZ</td>\n",
       "      <td>graham</td>\n",
       "      <td>4009</td>\n",
       "      <td>37529</td>\n",
       "      <td>51.461536</td>\n",
       "      <td>1.811932</td>\n",
       "      <td>32.097844</td>\n",
       "      <td>4.385942</td>\n",
       "      <td>46.313518</td>\n",
       "      <td>46.393456</td>\n",
       "      <td>12.315809</td>\n",
       "      <td>47422</td>\n",
       "      <td>14.424104</td>\n",
       "      <td>14.580797</td>\n",
       "      <td>86.675944</td>\n",
       "      <td>46.437399</td>\n",
       "      <td>3368</td>\n",
       "      <td>6870</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State    County  FIPS  Total Population  \\\n",
       "0    AZ    apache  4001             72346   \n",
       "1    AZ   cochise  4003            128177   \n",
       "2    AZ  coconino  4005            138064   \n",
       "3    AZ      gila  4007             53179   \n",
       "4    AZ    graham  4009             37529   \n",
       "\n",
       "   Percent White, not Hispanic or Latino  \\\n",
       "0                              18.571863   \n",
       "1                              56.299492   \n",
       "2                              54.619597   \n",
       "3                              63.222325   \n",
       "4                              51.461536   \n",
       "\n",
       "   Percent Black, not Hispanic or Latino  Percent Hispanic or Latino  \\\n",
       "0                               0.486551                    5.947806   \n",
       "1                               3.714395                   34.403208   \n",
       "2                               1.342855                   13.711033   \n",
       "3                               0.552850                   18.548675   \n",
       "4                               1.811932                   32.097844   \n",
       "\n",
       "   Percent Foreign Born  Percent Female  Percent Age 29 and Under  \\\n",
       "0              1.719515       50.598513                 45.854643   \n",
       "1             11.458374       49.069646                 37.902276   \n",
       "2              4.825298       50.581614                 48.946141   \n",
       "3              4.249798       50.296170                 32.238290   \n",
       "4              4.385942       46.313518                 46.393456   \n",
       "\n",
       "   Percent Age 65 and Older  Median Household Income  Percent Unemployed  \\\n",
       "0                 13.322091                    32460           15.807433   \n",
       "1                 19.756275                    45383            8.567108   \n",
       "2                 10.873943                    51106            8.238305   \n",
       "3                 26.397638                    40593           12.129932   \n",
       "4                 12.315809                    47422           14.424104   \n",
       "\n",
       "   Percent Less than High School Degree  Percent Less than Bachelor's Degree  \\\n",
       "0                             21.758252                            88.941063   \n",
       "1                             13.409171                            76.837055   \n",
       "2                             11.085381                            65.791439   \n",
       "3                             15.729958                            82.262624   \n",
       "4                             14.580797                            86.675944   \n",
       "\n",
       "   Percent Rural  Democratic  Republican  Party  \n",
       "0      74.061076       16298        7810      1  \n",
       "1      36.301067       17383       26929      0  \n",
       "2      31.466066       34240       19249      1  \n",
       "3      41.062000        7643       12180      0  \n",
       "4      46.437399        3368        6870      0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1195 entries, 0 to 1194\n",
      "Data columns (total 19 columns):\n",
      "State                                    1195 non-null object\n",
      "County                                   1195 non-null object\n",
      "FIPS                                     1195 non-null int64\n",
      "Total Population                         1195 non-null int64\n",
      "Percent White, not Hispanic or Latino    1195 non-null float64\n",
      "Percent Black, not Hispanic or Latino    1195 non-null float64\n",
      "Percent Hispanic or Latino               1195 non-null float64\n",
      "Percent Foreign Born                     1195 non-null float64\n",
      "Percent Female                           1195 non-null float64\n",
      "Percent Age 29 and Under                 1195 non-null float64\n",
      "Percent Age 65 and Older                 1195 non-null float64\n",
      "Median Household Income                  1195 non-null int64\n",
      "Percent Unemployed                       1195 non-null float64\n",
      "Percent Less than High School Degree     1195 non-null float64\n",
      "Percent Less than Bachelor's Degree      1195 non-null float64\n",
      "Percent Rural                            1195 non-null float64\n",
      "Democratic                               1195 non-null int64\n",
      "Republican                               1195 non-null int64\n",
      "Party                                    1195 non-null int64\n",
      "dtypes: float64(11), int64(6), object(2)\n",
      "memory usage: 177.5+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partition data into training and validation sets using holdout method\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(merged_train[['Total Population', 'Percent White, not Hispanic or Latino',\n",
    "                                                                 'Percent Black, not Hispanic or Latino', 'Percent Hispanic or Latino', 'Percent Foreign Born', \n",
    "                                                                 'Percent Female', 'Percent Age 29 and Under', 'Percent Age 65 and Older', 'Median Household Income', \n",
    "                                                                 'Percent Unemployed', 'Percent Less than High School Degree','Percent Less than Bachelor\\'s Degree', \n",
    "                                                                 'Percent Rural']], merged_train[['Democratic', 'Republican', 'Party']], train_size = .80, test_size = .20, \n",
    "                                                    random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 956 entries, 998 to 1061\n",
      "Data columns (total 13 columns):\n",
      "Total Population                         956 non-null int64\n",
      "Percent White, not Hispanic or Latino    956 non-null float64\n",
      "Percent Black, not Hispanic or Latino    956 non-null float64\n",
      "Percent Hispanic or Latino               956 non-null float64\n",
      "Percent Foreign Born                     956 non-null float64\n",
      "Percent Female                           956 non-null float64\n",
      "Percent Age 29 and Under                 956 non-null float64\n",
      "Percent Age 65 and Older                 956 non-null float64\n",
      "Median Household Income                  956 non-null int64\n",
      "Percent Unemployed                       956 non-null float64\n",
      "Percent Less than High School Degree     956 non-null float64\n",
      "Percent Less than Bachelor's Degree      956 non-null float64\n",
      "Percent Rural                            956 non-null float64\n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 104.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 239 entries, 49 to 775\n",
      "Data columns (total 13 columns):\n",
      "Total Population                         239 non-null int64\n",
      "Percent White, not Hispanic or Latino    239 non-null float64\n",
      "Percent Black, not Hispanic or Latino    239 non-null float64\n",
      "Percent Hispanic or Latino               239 non-null float64\n",
      "Percent Foreign Born                     239 non-null float64\n",
      "Percent Female                           239 non-null float64\n",
      "Percent Age 29 and Under                 239 non-null float64\n",
      "Percent Age 65 and Older                 239 non-null float64\n",
      "Median Household Income                  239 non-null int64\n",
      "Percent Unemployed                       239 non-null float64\n",
      "Percent Less than High School Degree     239 non-null float64\n",
      "Percent Less than Bachelor's Degree      239 non-null float64\n",
      "Percent Rural                            239 non-null float64\n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 26.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X_val.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 956 entries, 998 to 1061\n",
      "Data columns (total 3 columns):\n",
      "Democratic    956 non-null int64\n",
      "Republican    956 non-null int64\n",
      "Party         956 non-null int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 29.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing training and validation set\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building multiple regression model to predict the number of votes cast for the Democratic party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared for training set:          0.8752739904541752\n",
      "Adjusted R-squared for training set: 0.8735527185602308\n",
      "\n",
      "R-squared for validation set:          0.908288709568269\n",
      "Adjusted R-squared for validation set: 0.9029898350099912\n"
     ]
    }
   ],
   "source": [
    "#Using all predictors\n",
    "model = linear_model.LinearRegression()\n",
    "fitted_model1 = model.fit(X_train_scaled, Y_train['Democratic'])\n",
    "\n",
    "#Computing coefficient of determination(R squared) for training and validation sets \n",
    "score_train1 = fitted_model1.score(X_train_scaled, Y_train['Democratic'])\n",
    "score_val1 = fitted_model1.score(X_val_scaled, Y_val['Democratic'])\n",
    "\n",
    "#Computing Adjusted R2 for training and validation set\n",
    "adj_r_squared_train1 = 1 - (1-score_train1)*(len(Y_train)-1)/(len(Y_train) - X_train_scaled.shape[1]-1)\n",
    "adj_r_squared_val1 = 1 - (1-score_val1)*(len(Y_val)-1)/(len(Y_val) - X_val_scaled.shape[1]-1)\n",
    "\n",
    "print(\"R-squared for training set:          \" + str(score_train1))\n",
    "print(\"Adjusted R-squared for training set: \" + str(adj_r_squared_train1) + \"\\n\") \n",
    "\n",
    "print(\"R-squared for validation set:          \" + str(score_val1))\n",
    "print(\"Adjusted R-squared for validation set: \" + str(adj_r_squared_val1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64150.6121414  -3506.71204785  -861.95397823 -7086.83247197\n",
      "  3179.3708163   -224.16198629 -3763.37125336  -934.3301911\n",
      "   453.36600635   602.79108926  3360.0908122  -9019.33512776\n",
      "   504.05847238]\n"
     ]
    }
   ],
   "source": [
    "#Use LASSO regression to see which predictors can be dropped.\n",
    "model = linear_model.Lasso(alpha = 1)\n",
    "fitted_model = model.fit(X_train_scaled, Y_train['Democratic'])\n",
    "print(fitted_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64039.35518126 -3462.56802333  -818.85731052 -7045.62805782\n",
      "  3244.85157888  -211.34244833 -3764.89395411  -948.83678961\n",
      "   453.92431333   618.07264205  3303.53252191 -8993.18691584\n",
      "   493.83429229]\n"
     ]
    }
   ],
   "source": [
    "#Use Ridge regression to see which predictors can be dropped.\n",
    "#Ridge regression alleviates multicollinearity among predictor variables by shrinking \n",
    "#the coeffiecient estimates of highly correlated variables.\n",
    "model = linear_model.Ridge(alpha = 1)\n",
    "fitted_model = model.fit(X_train_scaled, Y_train['Democratic'])\n",
    "print(fitted_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared for training set:            0.8751984689166346\n",
      "Adjusted R-squared for training set:   0.8734761547934033\n",
      "\n",
      "R-squared for validation set:          0.9086512374205791\n",
      "Adjusted R-squared for validation set: 0.9033733089159903\n"
     ]
    }
   ],
   "source": [
    "#Using different set of predictors to predict the number of votes cast for the Democratic party\n",
    "#Dropping indices [2,5,8] since the coefficients of those indices are close to 0.\n",
    "model = linear_model.LinearRegression()\n",
    "predictor_indices = [0,1,3,4,6,7,9,10,11,12]\n",
    "fitted_model = model.fit(X_train_scaled[:,predictor_indices], Y_train['Democratic'])\n",
    "\n",
    "#Computing coefficient of determination(R squared) for training and validation sets \n",
    "score_train = fitted_model.score(X_train_scaled[:,predictor_indices], Y_train['Democratic'])\n",
    "score_val = fitted_model.score(X_val_scaled[:,predictor_indices], Y_val['Democratic'])\n",
    "\n",
    "#Computing Adjusted R2 for training and validation set\n",
    "adj_r_squared_train = 1 - (1-score_train)*(len(Y_train)-1)/(len(Y_train) - X_train_scaled.shape[1]-1)\n",
    "adj_r_squared_val = 1 - (1-score_val)*(len(Y_val)-1)/(len(Y_val) - X_val_scaled.shape[1]-1)\n",
    "\n",
    "print(\"R-squared for training set:            \" + str(score_train))\n",
    "print(\"Adjusted R-squared for training set:   \" + str(adj_r_squared_train) + \"\\n\")  \n",
    "\n",
    "print(\"R-squared for validation set:          \" + str(score_val))\n",
    "print(\"Adjusted R-squared for validation set: \" + str(adj_r_squared_val)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared for training set:            0.8734050605142323\n",
      "Adjusted R-squared for training set:   0.8716579965935157\n",
      "\n",
      "R-squared for validation set:          0.9147588775739619\n",
      "Adjusted R-squared for validation set: 0.9098338349449019\n"
     ]
    }
   ],
   "source": [
    "#Using different set of predictors to predict the number of votes cast for the Democratic party\n",
    "#Dropping indices [1,2,3,5,8] \n",
    "model = linear_model.LinearRegression()\n",
    "predictor_indices = [0,4,6,7,9,10,11,12]\n",
    "fitted_model = model.fit(X_train_scaled[:,predictor_indices], Y_train['Democratic'])\n",
    "\n",
    "#Computing coefficient of determination(R squared) for training and validation sets \n",
    "score_train = fitted_model.score(X_train_scaled[:,predictor_indices], Y_train['Democratic'])\n",
    "score_val = fitted_model.score(X_val_scaled[:,predictor_indices], Y_val['Democratic'])\n",
    "\n",
    "#Computing Adjusted R2 for training and validation set\n",
    "adj_r_squared_train = 1 - (1-score_train)*(len(Y_train)-1)/(len(Y_train) - X_train_scaled.shape[1]-1)\n",
    "adj_r_squared_val = 1 - (1-score_val)*(len(Y_val)-1)/(len(Y_val) - X_val_scaled.shape[1]-1)\n",
    "\n",
    "print(\"R-squared for training set:            \" + str(score_train))\n",
    "print(\"Adjusted R-squared for training set:   \" + str(adj_r_squared_train) + \"\\n\")  \n",
    "\n",
    "print(\"R-squared for validation set:          \" + str(score_val))\n",
    "print(\"Adjusted R-squared for validation set: \" + str(adj_r_squared_val)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building multiple regression model to predict the number of votes cast for the Republican party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared for training set:          0.8594179970051173\n",
      "Adjusted R-squared for training set: 0.8574779056686699\n",
      "\n",
      "R-squared for validation set:          0.8210331058190162\n",
      "Adjusted R-squared for validation set: 0.8106927963774483\n"
     ]
    }
   ],
   "source": [
    "#Using all predictors\n",
    "model = linear_model.LinearRegression()\n",
    "fitted_model1 = model.fit(X_train_scaled, Y_train['Republican'])\n",
    "\n",
    "#Computing coefficient of determination(R squared) for training and validation sets \n",
    "score_train1 = fitted_model1.score(X_train_scaled, Y_train['Republican'])\n",
    "score_val1 = fitted_model1.score(X_val_scaled, Y_val['Republican'])\n",
    "\n",
    "#Computing Adjusted R2 for training and validation set\n",
    "adj_r_squared_train1 = 1 - (1-score_train1)*(len(Y_train)-1)/(len(Y_train) - X_train_scaled.shape[1]-1)\n",
    "adj_r_squared_val1 = 1 - (1-score_val1)*(len(Y_val)-1)/(len(Y_val) - X_val_scaled.shape[1]-1)\n",
    "\n",
    "print(\"R-squared for training set:          \" + str(score_train1))\n",
    "print(\"Adjusted R-squared for training set: \" + str(adj_r_squared_train1) + \"\\n\") \n",
    "\n",
    "print(\"R-squared for validation set:          \" + str(score_val1))\n",
    "print(\"Adjusted R-squared for validation set: \" + str(adj_r_squared_val1)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38978.7948138   2024.49381171 -2413.30471919  1156.68157596\n",
      " -4570.21566866  -578.13156905  -727.82054541  2379.32041225\n",
      "  5134.4926651   2083.58869459  2732.86618891 -2718.56002563\n",
      " -5780.05192659]\n"
     ]
    }
   ],
   "source": [
    "#Use LASSO regression to see which predictors can be dropped. \n",
    "model = linear_model.Lasso(alpha = 1)\n",
    "fitted_model1 = model.fit(X_train_scaled, Y_train['Republican'])\n",
    "print(fitted_model1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38904.00476353  2021.97537385 -2399.34348487  1148.83745329\n",
      " -4509.30191166  -567.98712067  -749.609122    2345.75091792\n",
      "  5111.02926766  2084.74824044  2696.54141257 -2716.13638911\n",
      " -5774.36087734]\n"
     ]
    }
   ],
   "source": [
    "#Use Ridge regression to see which predictors can be dropped.\n",
    "#Ridge regression alleviates multicollinearity among predictor variables by shrinking \n",
    "#the coeffiecient estimates of highly correlated variables.\n",
    "model = linear_model.Ridge(alpha = 1)\n",
    "fitted_model = model.fit(X_train_scaled, Y_train['Republican'])\n",
    "print(fitted_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared for training set:            0.855651844770803\n",
      "Adjusted R-squared for training set:   0.8536597789343067\n",
      "\n",
      "R-squared for validation set:          0.8197195682603458\n",
      "Adjusted R-squared for validation set: 0.8093033655376102\n"
     ]
    }
   ],
   "source": [
    "#Using different set of predictors to predict the number of votes cast for the Republican party\n",
    "#Dropping indices [2,5,6,9,11] \n",
    "model = linear_model.LinearRegression()\n",
    "predictor_indices = [0,1,3,4,7,8,10,12]\n",
    "fitted_model2 = model.fit(X_train_scaled[:,predictor_indices], Y_train['Republican'])\n",
    "\n",
    "#Computing coefficient of determination(R squared) for training and validation sets \n",
    "score_train2 = fitted_model2.score(X_train_scaled[:,predictor_indices], Y_train['Republican'])\n",
    "score_val2 = fitted_model2.score(X_val_scaled[:,predictor_indices], Y_val['Republican'])\n",
    "\n",
    "#Computing Adjusted R2 for training and validation set\n",
    "adj_r_squared_train2 = 1 - (1-score_train2)*(len(Y_train)-1)/(len(Y_train) - X_train_scaled.shape[1]-1)\n",
    "adj_r_squared_val2 = 1 - (1-score_val2)*(len(Y_val)-1)/(len(Y_val) - X_val_scaled.shape[1]-1)\n",
    "\n",
    "print(\"R-squared for training set:            \" + str(score_train2))\n",
    "print(\"Adjusted R-squared for training set:   \" + str(adj_r_squared_train2) + \"\\n\")  \n",
    "\n",
    "print(\"R-squared for validation set:          \" + str(score_val2))\n",
    "print(\"Adjusted R-squared for validation set: \" + str(adj_r_squared_val2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared for training set:            0.8564653480641365\n",
      "Adjusted R-squared for training set:   0.8544845089185249\n",
      "\n",
      "R-squared for validation set:          0.8215035133009212\n",
      "Adjusted R-squared for validation set: 0.8111903829583078\n"
     ]
    }
   ],
   "source": [
    "#Using different set of predictors to predict the number of votes cast for the Republican party\n",
    "#Dropping indices [2,6,9]\n",
    "model = linear_model.LinearRegression()\n",
    "predictor_indices = [0,1,3,4,5,7,8,10,11,12]\n",
    "fitted_model2 = model.fit(X_train_scaled[:,predictor_indices], Y_train['Republican'])\n",
    "\n",
    "#Computing coefficient of determination(R squared) for training and validation sets \n",
    "score_train2 = fitted_model2.score(X_train_scaled[:,predictor_indices], Y_train['Republican'])\n",
    "score_val2 = fitted_model2.score(X_val_scaled[:,predictor_indices], Y_val['Republican'])\n",
    "\n",
    "#Computing Adjusted R2 for training and validation set\n",
    "adj_r_squared_train2 = 1 - (1-score_train2)*(len(Y_train)-1)/(len(Y_train) - X_train_scaled.shape[1]-1)\n",
    "adj_r_squared_val2 = 1 - (1-score_val2)*(len(Y_val)-1)/(len(Y_val) - X_val_scaled.shape[1]-1)\n",
    "\n",
    "print(\"R-squared for training set:            \" + str(score_train2))\n",
    "print(\"Adjusted R-squared for training set:   \" + str(adj_r_squared_train2) + \"\\n\")  \n",
    "\n",
    "print(\"R-squared for validation set:          \" + str(score_val2))\n",
    "print(\"Adjusted R-squared for validation set: \" + str(adj_r_squared_val2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building classification model using Naive Baye's technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best summed precision: 1.65359477124183 \n",
      "From columns: [0, 12] \n",
      "With split: [0.76470588 0.88888889] \n",
      "And jump: 7\n",
      "\n",
      "Best summed recall: 1.435844513243894 \n",
      "From columns: [1, 12] \n",
      "With split: [0.90643275 0.52941176] \n",
      "And jump: 5\n",
      "\n",
      "Best tot f1_score: 1.465921787709497 \n",
      "From columns: [1, 12] \n",
      "With split: [0.86592179 0.6       ] \n",
      "And jump: 5\n"
     ]
    }
   ],
   "source": [
    "#isolate what we are interested in, which is the party (0/1)\n",
    "classifier = GaussianNB()  \n",
    "\n",
    "y4_train = Y_train['Party']\n",
    "y4_val = Y_val['Party']\n",
    "\n",
    "min_cols = 0\n",
    "max_cols = len(X_train.columns)\n",
    "\n",
    "max_precision = -100\n",
    "best_precision_cols = []\n",
    "best_precision_split = []\n",
    "best_precision_jump = -100\n",
    "\n",
    "max_recall = -100\n",
    "best_recall_cols = []\n",
    "best_recall_split = []\n",
    "best_recall_jump = -100\n",
    "\n",
    "max_f1_score = -100\n",
    "best_f1_split = []\n",
    "best_cols = []\n",
    "best_f1_jump = -100\n",
    "\n",
    "# #for every possible set of columns, get their evaluation metrics\n",
    "jump = 1\n",
    "for start_col in range(min_cols, max_cols): #from 0 to 12 in range\n",
    "    for end_col in range(start_col+1, max_cols):#from from 1 to 13 in range\n",
    "        while jump != end_col: #we test intervals of variables too\n",
    "            x4_train_scaled = X_train_scaled[:,start_col:end_col:jump]\n",
    "            x4_val_scaled = X_val_scaled[:,start_col:end_col:jump]\n",
    "            classifier.fit(x4_train_scaled, y4_train)\n",
    "            y_pred = classifier.predict(x4_val_scaled)\n",
    "\n",
    "            #get some evaluation metrics for the classifier\n",
    "            accuracy = metrics.accuracy_score(y4_val, y_pred)\n",
    "            error = 1 - accuracy\n",
    "            precision = metrics.precision_score(y4_val, y_pred, average = None)\n",
    "            recall = metrics.recall_score(y4_val, y_pred, average = None)\n",
    "            F1_score = metrics.f1_score(y4_val, y_pred, average = None )\n",
    "\n",
    "            if max_precision <= sum(precision): #returns the last instance of best prec\n",
    "                max_precision = sum(precision)\n",
    "                best_precision_split = precision\n",
    "                best_precision_jump = jump                \n",
    "                best_precision_cols = [start_col, end_col]          \n",
    "\n",
    "            if max_recall <= sum(recall): #returns the last instance of best recall\n",
    "                max_recall = sum(recall)\n",
    "                best_recall_split = recall\n",
    "                best_recall_jump = jump\n",
    "                best_recall_cols = [start_col, end_col]     \n",
    "\n",
    "            if max_f1_score <= sum(F1_score): #returns the last instance of best f1 score\n",
    "                max_f1_score = sum(F1_score)\n",
    "                best_f1_split = F1_score\n",
    "                best_f1_jump = jump\n",
    "                best_cols = [start_col, end_col]\n",
    "            jump = jump + 1\n",
    "            \n",
    "#             print(\"\\nStart and end cols:\", [start_col, end_col],\n",
    "#                   \"\\nJump is:\", jump,\n",
    "#                   \"\\nAccuracy:\", accuracy,\n",
    "#                   \"\\nError:\", error,\n",
    "#                   \"\\nPrecision:\", precision,\n",
    "#                   \"\\nRecall:\", recall,\n",
    "#                   \"\\nF1:\", F1_score\n",
    "#                  )            \n",
    "        jump = 1\n",
    "\n",
    "print(\"\\nBest summed precision:\",max_precision, \n",
    "      \"\\nFrom columns:\", best_precision_cols,\n",
    "      \"\\nWith split:\", best_precision_split,\n",
    "      \"\\nAnd jump:\", best_precision_jump      \n",
    "     )\n",
    "print(\"\\nBest summed recall:\",max_recall, \n",
    "      \"\\nFrom columns:\", best_recall_cols,\n",
    "      \"\\nWith split:\", best_recall_split,\n",
    "      \"\\nAnd jump:\", best_recall_jump\n",
    "     )\n",
    "print(\"\\nBest tot f1_score:\", max_f1_score,\n",
    "      \"\\nFrom columns:\",best_cols,\n",
    "      \"\\nWith split:\",best_f1_split,\n",
    "      \"\\nAnd jump:\", best_f1_jump\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building classification model using K Nearest Neighbors method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best summed precision: 1.7038277511961724 \n",
      "Using neighbors = 2 \n",
      "From columns: [0, 5] \n",
      "With split: [0.80382775 0.9       ] \n",
      "And jump: 1\n",
      "\n",
      "Best summed recall: 1.5092019263845888 \n",
      "Using neighbors = 5 \n",
      "From columns: [0, 12] \n",
      "With split: [0.93567251 0.57352941] \n",
      "And jump: 1\n",
      "\n",
      "Best tot f1_score: 1.5499058380414312 \n",
      "Using neighbors = 5 \n",
      "From columns: [0, 12] \n",
      "With split: [0.88888889 0.66101695] \n",
      "And jump: 1\n"
     ]
    }
   ],
   "source": [
    "#isolate what we are interested in, which is the party (0/1)\n",
    "\n",
    "y4_train = Y_train['Party']\n",
    "y4_val = Y_val['Party']\n",
    "\n",
    "min_cols = 0\n",
    "max_cols = len(X_train.columns)\n",
    "\n",
    "max_precision = -100\n",
    "best_precision_cols = []\n",
    "best_precision_split = []\n",
    "best_precision_neighbors = -100\n",
    "best_precision_jump = -100\n",
    "\n",
    "max_recall = -100\n",
    "best_recall_cols = []\n",
    "best_recall_split = []\n",
    "best_recall_neighbors = -100\n",
    "best_recall_jump = -100\n",
    "\n",
    "max_f1_score = -100\n",
    "best_f1_split = []\n",
    "best_cols = []\n",
    "best_f1_neighbors = -100\n",
    "best_f1_jump = -100\n",
    "\n",
    "jump = 1\n",
    "#for every possible set of columns and neighbors 1-5, get their evaluation metrics\n",
    "for start_col in range(min_cols, max_cols-1): #from 0 to 12 in range\n",
    "    for end_col in range(start_col+1, max_cols):#from 1 to 13 in range\n",
    "        while jump != end_col: #we test intervals of variables too        \n",
    "            x4_train_scaled = X_train_scaled[:,start_col:end_col:jump]\n",
    "            x4_val_scaled = X_val_scaled[:,start_col:end_col:jump]\n",
    "\n",
    "            #for number of neighbors from 1 to 5\n",
    "            for neighbors in range(1,6):\n",
    "#                 print(start_col, end_col, jump, neighbors)\n",
    "                classifier = KNeighborsClassifier(n_neighbors = neighbors)  \n",
    "                classifier.fit(x4_train_scaled, y4_train)\n",
    "\n",
    "                y_pred = classifier.predict(x4_val_scaled)\n",
    "\n",
    "                #get some evaluation metrics for the classifier\n",
    "                accuracy = metrics.accuracy_score(y4_val, y_pred)\n",
    "                error = 1 - accuracy\n",
    "                precision = metrics.precision_score(y4_val, y_pred, average = None)\n",
    "                recall = metrics.recall_score(y4_val, y_pred, average = None)\n",
    "                F1_score = metrics.f1_score(y4_val, y_pred, average = None )\n",
    "\n",
    "                if max_precision <= sum(precision): #returns the last instance of best prec\n",
    "                    max_precision = sum(precision)\n",
    "                    best_precision_split = precision\n",
    "                    best_precision_neighbors = neighbors\n",
    "                    best_precision_jump = jump\n",
    "                    best_precision_cols = [start_col, end_col]          \n",
    "\n",
    "                if max_recall <= sum(recall): #returns the last instance of best recall\n",
    "                    max_recall = sum(recall)\n",
    "                    best_recall_split = recall\n",
    "                    best_recall_neighbors = neighbors     \n",
    "                    best_recall_jump = jump                    \n",
    "                    best_recall_cols = [start_col, end_col]     \n",
    "\n",
    "                if max_f1_score <= sum(F1_score): #returns the last instance of best f1 score\n",
    "                    max_f1_score = sum(F1_score)\n",
    "                    best_f1_split = F1_score\n",
    "                    best_f1_neighbors = neighbors\n",
    "                    best_f1_jump = jump\n",
    "                    best_cols = [start_col, end_col]\n",
    "\n",
    "    #             print(\"\\nStart and end cols:\", [start_col, end_col],\n",
    "    #                   \"\\nAccuracy:\", accuracy,\n",
    "    #                   \"\\nError:\", error,\n",
    "    #                   \"\\nPrecision:\", precision,\n",
    "    #                   \"\\nRecall:\", recall,\n",
    "    #                   \"\\nF1:\", F1_score\n",
    "    #                  )\n",
    "            jump = jump + 1\n",
    "        jump = 1\n",
    "\n",
    "print(\"\\nBest summed precision:\",max_precision, \n",
    "      \"\\nUsing neighbors =\", best_precision_neighbors,\n",
    "      \"\\nFrom columns:\", best_precision_cols,\n",
    "      \"\\nWith split:\", best_precision_split,\n",
    "      \"\\nAnd jump:\", best_precision_jump     \n",
    "     )\n",
    "print(\"\\nBest summed recall:\",max_recall, \n",
    "      \"\\nUsing neighbors =\", best_recall_neighbors,      \n",
    "      \"\\nFrom columns:\", best_recall_cols,\n",
    "      \"\\nWith split:\", best_recall_split,\n",
    "      \"\\nAnd jump:\", best_recall_jump      \n",
    "     )\n",
    "print(\"\\nBest tot f1_score:\", max_f1_score,\n",
    "      \"\\nUsing neighbors =\", best_f1_neighbors,      \n",
    "      \"\\nFrom columns:\",best_cols,\n",
    "      \"\\nWith split:\",best_f1_split,\n",
    "      \"\\nAnd jump:\", best_f1_jump\n",
    "     )            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Percent White, not Hispanic or Latino</th>\n",
       "      <th>Percent Black, not Hispanic or Latino</th>\n",
       "      <th>Percent Hispanic or Latino</th>\n",
       "      <th>Percent Foreign Born</th>\n",
       "      <th>Percent Female</th>\n",
       "      <th>Percent Age 29 and Under</th>\n",
       "      <th>Percent Age 65 and Older</th>\n",
       "      <th>Median Household Income</th>\n",
       "      <th>Percent Unemployed</th>\n",
       "      <th>Percent Less than High School Degree</th>\n",
       "      <th>Percent Less than Bachelor's Degree</th>\n",
       "      <th>Percent Rural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>13122</td>\n",
       "      <td>85.208048</td>\n",
       "      <td>7.117817</td>\n",
       "      <td>2.217650</td>\n",
       "      <td>1.798506</td>\n",
       "      <td>51.150739</td>\n",
       "      <td>34.644109</td>\n",
       "      <td>20.423716</td>\n",
       "      <td>48271</td>\n",
       "      <td>5.308192</td>\n",
       "      <td>14.155202</td>\n",
       "      <td>74.355116</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>123601</td>\n",
       "      <td>84.768732</td>\n",
       "      <td>1.466817</td>\n",
       "      <td>11.155250</td>\n",
       "      <td>4.481355</td>\n",
       "      <td>50.174351</td>\n",
       "      <td>38.469753</td>\n",
       "      <td>14.703765</td>\n",
       "      <td>67979</td>\n",
       "      <td>5.564726</td>\n",
       "      <td>10.735275</td>\n",
       "      <td>72.974767</td>\n",
       "      <td>56.084566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>9055</td>\n",
       "      <td>88.812811</td>\n",
       "      <td>0.077305</td>\n",
       "      <td>9.607951</td>\n",
       "      <td>4.538929</td>\n",
       "      <td>49.442297</td>\n",
       "      <td>36.775262</td>\n",
       "      <td>21.258973</td>\n",
       "      <td>49181</td>\n",
       "      <td>2.541847</td>\n",
       "      <td>12.288761</td>\n",
       "      <td>80.049221</td>\n",
       "      <td>65.204070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>21026</td>\n",
       "      <td>92.304766</td>\n",
       "      <td>4.418339</td>\n",
       "      <td>1.664606</td>\n",
       "      <td>0.799011</td>\n",
       "      <td>46.142871</td>\n",
       "      <td>35.608294</td>\n",
       "      <td>16.313136</td>\n",
       "      <td>43786</td>\n",
       "      <td>5.646527</td>\n",
       "      <td>13.624489</td>\n",
       "      <td>87.340076</td>\n",
       "      <td>78.961583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>48713</td>\n",
       "      <td>92.858169</td>\n",
       "      <td>1.426724</td>\n",
       "      <td>2.566050</td>\n",
       "      <td>2.147271</td>\n",
       "      <td>51.187568</td>\n",
       "      <td>43.039846</td>\n",
       "      <td>15.178700</td>\n",
       "      <td>50910</td>\n",
       "      <td>5.166842</td>\n",
       "      <td>9.569456</td>\n",
       "      <td>75.217562</td>\n",
       "      <td>44.273958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>6314</td>\n",
       "      <td>93.633196</td>\n",
       "      <td>3.515996</td>\n",
       "      <td>0.316756</td>\n",
       "      <td>0.427621</td>\n",
       "      <td>51.013621</td>\n",
       "      <td>30.725372</td>\n",
       "      <td>21.808679</td>\n",
       "      <td>49496</td>\n",
       "      <td>5.757970</td>\n",
       "      <td>13.885899</td>\n",
       "      <td>82.777180</td>\n",
       "      <td>99.874253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>1520</td>\n",
       "      <td>81.052632</td>\n",
       "      <td>0.328947</td>\n",
       "      <td>15.131579</td>\n",
       "      <td>2.105263</td>\n",
       "      <td>53.355263</td>\n",
       "      <td>28.684211</td>\n",
       "      <td>27.960526</td>\n",
       "      <td>39438</td>\n",
       "      <td>3.133903</td>\n",
       "      <td>19.432121</td>\n",
       "      <td>80.124224</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>27669</td>\n",
       "      <td>94.614912</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>2.753985</td>\n",
       "      <td>2.519065</td>\n",
       "      <td>50.663197</td>\n",
       "      <td>26.556796</td>\n",
       "      <td>26.611009</td>\n",
       "      <td>53980</td>\n",
       "      <td>5.862044</td>\n",
       "      <td>6.365714</td>\n",
       "      <td>68.675092</td>\n",
       "      <td>68.986863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>195201</td>\n",
       "      <td>69.806507</td>\n",
       "      <td>18.171526</td>\n",
       "      <td>8.198216</td>\n",
       "      <td>2.376525</td>\n",
       "      <td>51.494101</td>\n",
       "      <td>38.538737</td>\n",
       "      <td>17.154625</td>\n",
       "      <td>43712</td>\n",
       "      <td>9.535561</td>\n",
       "      <td>11.528984</td>\n",
       "      <td>79.273610</td>\n",
       "      <td>31.118205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>2231</td>\n",
       "      <td>92.245630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.316898</td>\n",
       "      <td>1.389511</td>\n",
       "      <td>50.605110</td>\n",
       "      <td>32.093232</td>\n",
       "      <td>22.456298</td>\n",
       "      <td>51395</td>\n",
       "      <td>4.411765</td>\n",
       "      <td>3.577926</td>\n",
       "      <td>75.803517</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>956 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Total Population  Percent White, not Hispanic or Latino  \\\n",
       "998              13122                              85.208048   \n",
       "875             123601                              84.768732   \n",
       "401               9055                              88.812811   \n",
       "134              21026                              92.304766   \n",
       "509              48713                              92.858169   \n",
       "...                ...                                    ...   \n",
       "715               6314                              93.633196   \n",
       "905               1520                              81.052632   \n",
       "1096             27669                              94.614912   \n",
       "235             195201                              69.806507   \n",
       "1061              2231                              92.245630   \n",
       "\n",
       "      Percent Black, not Hispanic or Latino  Percent Hispanic or Latino  \\\n",
       "998                                7.117817                    2.217650   \n",
       "875                                1.466817                   11.155250   \n",
       "401                                0.077305                    9.607951   \n",
       "134                                4.418339                    1.664606   \n",
       "509                                1.426724                    2.566050   \n",
       "...                                     ...                         ...   \n",
       "715                                3.515996                    0.316756   \n",
       "905                                0.328947                   15.131579   \n",
       "1096                               0.509596                    2.753985   \n",
       "235                               18.171526                    8.198216   \n",
       "1061                               0.000000                    3.316898   \n",
       "\n",
       "      Percent Foreign Born  Percent Female  Percent Age 29 and Under  \\\n",
       "998               1.798506       51.150739                 34.644109   \n",
       "875               4.481355       50.174351                 38.469753   \n",
       "401               4.538929       49.442297                 36.775262   \n",
       "134               0.799011       46.142871                 35.608294   \n",
       "509               2.147271       51.187568                 43.039846   \n",
       "...                    ...             ...                       ...   \n",
       "715               0.427621       51.013621                 30.725372   \n",
       "905               2.105263       53.355263                 28.684211   \n",
       "1096              2.519065       50.663197                 26.556796   \n",
       "235               2.376525       51.494101                 38.538737   \n",
       "1061              1.389511       50.605110                 32.093232   \n",
       "\n",
       "      Percent Age 65 and Older  Median Household Income  Percent Unemployed  \\\n",
       "998                  20.423716                    48271            5.308192   \n",
       "875                  14.703765                    67979            5.564726   \n",
       "401                  21.258973                    49181            2.541847   \n",
       "134                  16.313136                    43786            5.646527   \n",
       "509                  15.178700                    50910            5.166842   \n",
       "...                        ...                      ...                 ...   \n",
       "715                  21.808679                    49496            5.757970   \n",
       "905                  27.960526                    39438            3.133903   \n",
       "1096                 26.611009                    53980            5.862044   \n",
       "235                  17.154625                    43712            9.535561   \n",
       "1061                 22.456298                    51395            4.411765   \n",
       "\n",
       "      Percent Less than High School Degree  \\\n",
       "998                              14.155202   \n",
       "875                              10.735275   \n",
       "401                              12.288761   \n",
       "134                              13.624489   \n",
       "509                               9.569456   \n",
       "...                                    ...   \n",
       "715                              13.885899   \n",
       "905                              19.432121   \n",
       "1096                              6.365714   \n",
       "235                              11.528984   \n",
       "1061                              3.577926   \n",
       "\n",
       "      Percent Less than Bachelor's Degree  Percent Rural  \n",
       "998                             74.355116     100.000000  \n",
       "875                             72.974767      56.084566  \n",
       "401                             80.049221      65.204070  \n",
       "134                             87.340076      78.961583  \n",
       "509                             75.217562      44.273958  \n",
       "...                                   ...            ...  \n",
       "715                             82.777180      99.874253  \n",
       "905                             80.124224     100.000000  \n",
       "1096                            68.675092      68.986863  \n",
       "235                             79.273610      31.118205  \n",
       "1061                            75.803517     100.000000  \n",
       "\n",
       "[956 rows x 13 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from sklearn.cluster import KMeans, DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Percent White, not Hispanic or Latino</th>\n",
       "      <th>Percent Black, not Hispanic or Latino</th>\n",
       "      <th>Percent Hispanic or Latino</th>\n",
       "      <th>Percent Foreign Born</th>\n",
       "      <th>Percent Female</th>\n",
       "      <th>Percent Age 29 and Under</th>\n",
       "      <th>Percent Age 65 and Older</th>\n",
       "      <th>Median Household Income</th>\n",
       "      <th>Percent Unemployed</th>\n",
       "      <th>Percent Less than High School Degree</th>\n",
       "      <th>Percent Less than Bachelor's Degree</th>\n",
       "      <th>Percent Rural</th>\n",
       "      <th>Democratic</th>\n",
       "      <th>Republican</th>\n",
       "      <th>Party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AZ</td>\n",
       "      <td>apache</td>\n",
       "      <td>4001</td>\n",
       "      <td>72346</td>\n",
       "      <td>18.571863</td>\n",
       "      <td>0.486551</td>\n",
       "      <td>5.947806</td>\n",
       "      <td>1.719515</td>\n",
       "      <td>50.598513</td>\n",
       "      <td>45.854643</td>\n",
       "      <td>13.322091</td>\n",
       "      <td>32460</td>\n",
       "      <td>15.807433</td>\n",
       "      <td>21.758252</td>\n",
       "      <td>88.941063</td>\n",
       "      <td>74.061076</td>\n",
       "      <td>16298</td>\n",
       "      <td>7810</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZ</td>\n",
       "      <td>cochise</td>\n",
       "      <td>4003</td>\n",
       "      <td>128177</td>\n",
       "      <td>56.299492</td>\n",
       "      <td>3.714395</td>\n",
       "      <td>34.403208</td>\n",
       "      <td>11.458374</td>\n",
       "      <td>49.069646</td>\n",
       "      <td>37.902276</td>\n",
       "      <td>19.756275</td>\n",
       "      <td>45383</td>\n",
       "      <td>8.567108</td>\n",
       "      <td>13.409171</td>\n",
       "      <td>76.837055</td>\n",
       "      <td>36.301067</td>\n",
       "      <td>17383</td>\n",
       "      <td>26929</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>coconino</td>\n",
       "      <td>4005</td>\n",
       "      <td>138064</td>\n",
       "      <td>54.619597</td>\n",
       "      <td>1.342855</td>\n",
       "      <td>13.711033</td>\n",
       "      <td>4.825298</td>\n",
       "      <td>50.581614</td>\n",
       "      <td>48.946141</td>\n",
       "      <td>10.873943</td>\n",
       "      <td>51106</td>\n",
       "      <td>8.238305</td>\n",
       "      <td>11.085381</td>\n",
       "      <td>65.791439</td>\n",
       "      <td>31.466066</td>\n",
       "      <td>34240</td>\n",
       "      <td>19249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AZ</td>\n",
       "      <td>gila</td>\n",
       "      <td>4007</td>\n",
       "      <td>53179</td>\n",
       "      <td>63.222325</td>\n",
       "      <td>0.552850</td>\n",
       "      <td>18.548675</td>\n",
       "      <td>4.249798</td>\n",
       "      <td>50.296170</td>\n",
       "      <td>32.238290</td>\n",
       "      <td>26.397638</td>\n",
       "      <td>40593</td>\n",
       "      <td>12.129932</td>\n",
       "      <td>15.729958</td>\n",
       "      <td>82.262624</td>\n",
       "      <td>41.062000</td>\n",
       "      <td>7643</td>\n",
       "      <td>12180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AZ</td>\n",
       "      <td>graham</td>\n",
       "      <td>4009</td>\n",
       "      <td>37529</td>\n",
       "      <td>51.461536</td>\n",
       "      <td>1.811932</td>\n",
       "      <td>32.097844</td>\n",
       "      <td>4.385942</td>\n",
       "      <td>46.313518</td>\n",
       "      <td>46.393456</td>\n",
       "      <td>12.315809</td>\n",
       "      <td>47422</td>\n",
       "      <td>14.424104</td>\n",
       "      <td>14.580797</td>\n",
       "      <td>86.675944</td>\n",
       "      <td>46.437399</td>\n",
       "      <td>3368</td>\n",
       "      <td>6870</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State    County  FIPS  Total Population  \\\n",
       "0    AZ    apache  4001             72346   \n",
       "1    AZ   cochise  4003            128177   \n",
       "2    AZ  coconino  4005            138064   \n",
       "3    AZ      gila  4007             53179   \n",
       "4    AZ    graham  4009             37529   \n",
       "\n",
       "   Percent White, not Hispanic or Latino  \\\n",
       "0                              18.571863   \n",
       "1                              56.299492   \n",
       "2                              54.619597   \n",
       "3                              63.222325   \n",
       "4                              51.461536   \n",
       "\n",
       "   Percent Black, not Hispanic or Latino  Percent Hispanic or Latino  \\\n",
       "0                               0.486551                    5.947806   \n",
       "1                               3.714395                   34.403208   \n",
       "2                               1.342855                   13.711033   \n",
       "3                               0.552850                   18.548675   \n",
       "4                               1.811932                   32.097844   \n",
       "\n",
       "   Percent Foreign Born  Percent Female  Percent Age 29 and Under  \\\n",
       "0              1.719515       50.598513                 45.854643   \n",
       "1             11.458374       49.069646                 37.902276   \n",
       "2              4.825298       50.581614                 48.946141   \n",
       "3              4.249798       50.296170                 32.238290   \n",
       "4              4.385942       46.313518                 46.393456   \n",
       "\n",
       "   Percent Age 65 and Older  Median Household Income  Percent Unemployed  \\\n",
       "0                 13.322091                    32460           15.807433   \n",
       "1                 19.756275                    45383            8.567108   \n",
       "2                 10.873943                    51106            8.238305   \n",
       "3                 26.397638                    40593           12.129932   \n",
       "4                 12.315809                    47422           14.424104   \n",
       "\n",
       "   Percent Less than High School Degree  Percent Less than Bachelor's Degree  \\\n",
       "0                             21.758252                            88.941063   \n",
       "1                             13.409171                            76.837055   \n",
       "2                             11.085381                            65.791439   \n",
       "3                             15.729958                            82.262624   \n",
       "4                             14.580797                            86.675944   \n",
       "\n",
       "   Percent Rural  Democratic  Republican  Party  \n",
       "0      74.061076       16298        7810      1  \n",
       "1      36.301067       17383       26929      0  \n",
       "2      31.466066       34240       19249      1  \n",
       "3      41.062000        7643       12180      0  \n",
       "4      46.437399        3368        6870      0  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing training and validation set\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#we work off the whole dataset, so we do not look at the already partitioned data\n",
    "Y_set = merged_train[['Democratic','Republican','Party','FIPS']] #what we are looking to predict\n",
    "Y_set_party = Y_set['Party']\n",
    "\n",
    "X_set = merged_train.drop(Y_set, axis=1) #remove the val set from test set\n",
    "X_set = X_set.drop(['State','County'], axis=1) #remove non-numeric values\n",
    "\n",
    "scaler.fit(X_set)\n",
    "t6_scaled = scaler.transform(X_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a clustering model using hierarchial clustering technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highest adjusted rand index: 0.2787940184428421 \n",
      "From start and end cols: [1, 12] \n",
      "With jump: 5 \n",
      "Using method: ward \n",
      "With silhouette: 0.42014830636625256\n",
      "\n",
      "Highest silhouette coefficient: 0.9203368814854908 \n",
      "From start and end cols: [5, 12] \n",
      "With jump: 11 \n",
      "Using method: average \n",
      "With rand index: -0.001047512629882871\n",
      "\n",
      "Highest total score: 0.9227984520332011 \n",
      "From start and end cols: [0, 12] \n",
      "With jump: 11 \n",
      "Using method: ward \n",
      "With index and coefficient: [0.26552201280751675, 0.6572764392256844]\n"
     ]
    }
   ],
   "source": [
    "methods = ['single','complete','average','ward']\n",
    "\n",
    "min_cols = 0\n",
    "max_cols = len(X_set.columns)\n",
    "\n",
    "best_rand = -100\n",
    "best_rand_set = []\n",
    "best_rand_jump = -999\n",
    "best_rand_method = ''\n",
    "best_rand_silh = -100\n",
    "\n",
    "best_silh = -100\n",
    "best_silh_set = []\n",
    "best_silh_jump = -999\n",
    "best_silh_method = ''\n",
    "best_silh_rand = -100\n",
    "\n",
    "best_tot_score = -100\n",
    "best_tot_set = []\n",
    "best_tot_jump = -999\n",
    "best_tot_method = ''\n",
    "best_tot_sections = []\n",
    "\n",
    "jump = 1\n",
    "#for every possible set of columns a\n",
    "for start_col in range(min_cols, max_cols-1): #from 0 to 12 in range\n",
    "    for end_col in range(start_col+1, max_cols):#from 1 to 13 in range\n",
    "        while jump != end_col:\n",
    "            t6_scaled_iter = t6_scaled[:,start_col:end_col:jump] #set the columns we will use \n",
    "        \n",
    "            #applying our clustering techniques\n",
    "            for method in methods: #make changes to each criteria\n",
    "                clustering = linkage(t6_scaled_iter, method = method, metric = \"euclidean\")\n",
    "                clusters = fcluster(clustering, 2, criterion = \"maxclust\")\n",
    "\n",
    "                #supervised evaluation metric\n",
    "                adjusted_rand_index = metrics.adjusted_rand_score(Y_set_party, clusters)\n",
    "                \n",
    "                #unsupervised evaluation metric\n",
    "                silhouette_coefficient = metrics.silhouette_score(t6_scaled_iter, clusters, metric = \"euclidean\")\n",
    "                \n",
    "#                 print([start_col, end_col, jump, method])\n",
    "                \n",
    "                if adjusted_rand_index >= best_rand:\n",
    "                    best_rand = adjusted_rand_index\n",
    "                    best_rand_set = [start_col,end_col]\n",
    "                    best_rand_jump = jump\n",
    "                    best_rand_method = method\n",
    "                    best_rand_silh = silhouette_coefficient\n",
    "                    \n",
    "                if silhouette_coefficient >= best_silh:\n",
    "                    best_silh = silhouette_coefficient\n",
    "                    best_silh_set = [start_col, end_col]\n",
    "                    best_silh_jump = jump\n",
    "                    best_silh_method = method\n",
    "                    best_silh_rand = adjusted_rand_index\n",
    "                    \n",
    "                curr_tot_score = adjusted_rand_index + silhouette_coefficient\n",
    "        \n",
    "                if curr_tot_score >= best_tot_score:\n",
    "                    best_tot_score = curr_tot_score\n",
    "                    best_tot_set = [start_col, end_col]\n",
    "                    best_tot_jump = jump\n",
    "                    best_tot_method = method\n",
    "                    best_tot_sections = [adjusted_rand_index, silhouette_coefficient]\n",
    "                    \n",
    "#                 print([adjusted_rand_index, silhouette_coefficient])\n",
    "#                 print(\"Start and end cols:\", [start_col, end_col],\n",
    "#                       \"\\nJump:\", jump,\n",
    "#                       \"\\nMethod for linkage:\", method,\n",
    "#                       \"\\nAdjusted rand_index:\", adjusted_rand_index,\n",
    "#                       \"\\nSilhouette coeff:\", silhouette_coefficient\n",
    "#                      )\n",
    "\n",
    "            jump = jump + 1\n",
    "        jump = 1\n",
    "        \n",
    "#we want a high adjusted rand index, as close to to 1 as possible\n",
    "print(\"\\nHighest adjusted rand index:\", best_rand,\n",
    "      \"\\nFrom start and end cols:\", best_rand_set,\n",
    "      \"\\nWith jump:\", best_rand_jump,\n",
    "      \"\\nUsing method:\", best_rand_method,\n",
    "      \"\\nWith silhouette:\", best_rand_silh\n",
    "     )\n",
    "#we want a high silhouette coefficient, as close to 1 as possible\n",
    "print(\"\\nHighest silhouette coefficient:\", best_silh,\n",
    "      \"\\nFrom start and end cols:\", best_silh_set,\n",
    "      \"\\nWith jump:\", best_silh_jump,\n",
    "      \"\\nUsing method:\", best_silh_method,\n",
    "      \"\\nWith rand index:\", best_silh_rand\n",
    "     )\n",
    "\n",
    "#we want the highest max double number\n",
    "print(\"\\nHighest total score:\", best_tot_score,\n",
    "      \"\\nFrom start and end cols:\", best_tot_set,\n",
    "      \"\\nWith jump:\", best_tot_jump,\n",
    "      \"\\nUsing method:\", best_tot_method,\n",
    "      \"\\nWith index and coefficient:\", best_tot_sections\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building clustering model using K-means clustering technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highest adjusted rand index: 0.19986515209658928 \n",
      "From start and end cols: [11, 12] \n",
      "With jump: 11 \n",
      "Using initialization: random \n",
      "With silhouette: 0.5819454743258012\n",
      "\n",
      "Highest silhouette coefficient: 0.5819454743258012 \n",
      "From start and end cols: [11, 12] \n",
      "With jump: 11 \n",
      "Using initialization: random \n",
      "With rand index: 0.19986515209658928\n",
      "\n",
      "Highest total score: 0.7818106264223905 \n",
      "From start and end cols: [11, 12] \n",
      "With jump: 11 \n",
      "Using initialization: random \n",
      "With index and coefficient: [0.19986515209658928, 0.5819454743258012]\n"
     ]
    }
   ],
   "source": [
    "inits = ['k-means++','random']\n",
    "\n",
    "min_cols = 0\n",
    "max_cols = len(X_set.columns)\n",
    "\n",
    "best_rand = -100\n",
    "best_rand_set = []\n",
    "best_rand_jump = -999\n",
    "best_rand_method = ''\n",
    "best_rand_silh = -100\n",
    "\n",
    "best_silh = -100\n",
    "best_silh_set = []\n",
    "best_silh_jump = -999\n",
    "best_silh_method = ''\n",
    "best_silh_rand = -100\n",
    "\n",
    "best_tot_score = -100\n",
    "best_tot_set = []\n",
    "best_tot_jump = -999\n",
    "best_tot_method = ''\n",
    "best_tot_sections = []\n",
    "\n",
    "jump = 1\n",
    "#for every possible set of columns a\n",
    "for start_col in range(min_cols, max_cols-1): #from 0 to 12 in range\n",
    "    for end_col in range(start_col+1, max_cols):#from 1 to 13 in range\n",
    "        while jump != end_col:\n",
    "            t6_scaled_iter = t6_scaled[:,start_col:end_col:jump] #set the columns we will use \n",
    "        \n",
    "            #applying our clustering techniques\n",
    "            for the_init in inits: #make changes to each criteria\n",
    "                #for time brevity, we choose n_init as 5\n",
    "                #we should ideally have n_clusters = 2, one for dem, one for rep\n",
    "                clustering = KMeans(n_clusters = 2,\n",
    "                                    init = the_init, \n",
    "                                    random_state = 0, \n",
    "                                    n_init = 5).fit(t6_scaled\n",
    "                                    )\n",
    "\n",
    "                #supervised evaluation metric\n",
    "                adjusted_rand_index = metrics.adjusted_rand_score(Y_set_party, clusters)\n",
    "                \n",
    "                #unsupervised evaluation metric\n",
    "                silhouette_coefficient = metrics.silhouette_score(t6_scaled_iter, clusters, metric = \"euclidean\")\n",
    "                \n",
    "#                 print([start_col, end_col, jump, method])\n",
    "                \n",
    "                if adjusted_rand_index >= best_rand:\n",
    "                    best_rand = adjusted_rand_index\n",
    "                    best_rand_set = [start_col,end_col]\n",
    "                    best_rand_jump = jump\n",
    "                    best_rand_method = the_init\n",
    "                    best_rand_silh = silhouette_coefficient\n",
    "                    \n",
    "                if silhouette_coefficient >= best_silh:\n",
    "                    best_silh = silhouette_coefficient\n",
    "                    best_silh_set = [start_col, end_col]\n",
    "                    best_silh_jump = jump\n",
    "                    best_silh_method = the_init\n",
    "                    best_silh_rand = adjusted_rand_index\n",
    "                    \n",
    "                curr_tot_score = adjusted_rand_index + silhouette_coefficient\n",
    "        \n",
    "                if curr_tot_score >= best_tot_score:\n",
    "                    best_tot_score = curr_tot_score\n",
    "                    best_tot_set = [start_col, end_col]\n",
    "                    best_tot_jump = jump\n",
    "                    best_tot_method = the_init\n",
    "                    best_tot_sections = [adjusted_rand_index, silhouette_coefficient]\n",
    "                    \n",
    "#                 print([adjusted_rand_index, silhouette_coefficient])\n",
    "#                 print(\"Start and end cols:\", [start_col, end_col],\n",
    "#                       \"\\nJump:\", jump,\n",
    "#                       \"\\nMethod for linkage:\", method,\n",
    "#                       \"\\nAdjusted rand_index:\", adjusted_rand_index,\n",
    "#                       \"\\nSilhouette coeff:\", silhouette_coefficient\n",
    "#                      )\n",
    "\n",
    "            jump = jump + 1\n",
    "        jump = 1\n",
    "        \n",
    "#we want a high adjusted rand index, as close to to 1 as possible\n",
    "print(\"\\nHighest adjusted rand index:\", best_rand,\n",
    "      \"\\nFrom start and end cols:\", best_rand_set,\n",
    "      \"\\nWith jump:\", best_rand_jump,\n",
    "      \"\\nUsing initialization:\", best_rand_method,\n",
    "      \"\\nWith silhouette:\", best_rand_silh\n",
    "     )\n",
    "#we want a high silhouette coefficient, as close to 1 as possible\n",
    "print(\"\\nHighest silhouette coefficient:\", best_silh,\n",
    "      \"\\nFrom start and end cols:\", best_silh_set,\n",
    "      \"\\nWith jump:\", best_silh_jump,\n",
    "      \"\\nUsing initialization:\", best_silh_method,\n",
    "      \"\\nWith rand index:\", best_silh_rand\n",
    "     )\n",
    "\n",
    "#we want the highest max double number\n",
    "print(\"\\nHighest total score:\", best_tot_score,\n",
    "      \"\\nFrom start and end cols:\", best_tot_set,\n",
    "      \"\\nWith jump:\", best_tot_jump,\n",
    "      \"\\nUsing initialization:\", best_tot_method,\n",
    "      \"\\nWith index and coefficient:\", best_tot_sections\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91620728 0.73611111]\n"
     ]
    }
   ],
   "source": [
    "#Dropping columns which cannot be standardized\n",
    "new_merged_train = merged_train.drop(columns = ['State','County','FIPS','Democratic','Republican','Party'])\n",
    "\n",
    "#Standardizing the whole merged_train dataset with numerical columns\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(new_merged_train)\n",
    "merged_train_scaled = scaler.transform(new_merged_train)\n",
    "\n",
    "#Rebuilding our best classification model which we found in task 4 on standardized merged_train dataset.\n",
    "predictor_indices = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "x6_train_scaled = X_train_scaled[:,predictor_indices]\n",
    "y6_train = Y_train['Party']\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5)  \n",
    "classifier.fit(x6_train_scaled, y6_train)\n",
    "\n",
    "Y_pred = classifier.predict(merged_train_scaled[:,predictor_indices])\n",
    "F1_score = metrics.f1_score(merged_train['Party'], Y_pred, average = None )\n",
    "print(F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "fips = merged_train['FIPS']\n",
    "vals = Y_pred.tolist()\n",
    "\n",
    "#Converting values of 1's and 0's to Democratic and Republican respectively.\n",
    "for x in range(0, len(vals)):\n",
    "    if vals[x] == 1:\n",
    "        vals[x] = 'Democratic'\n",
    "    if vals[x] == 0:\n",
    "        vals[x] = 'Republican'\n",
    "\n",
    "colorscale = ['rgb(0,0,255)','rgb(255,0,0)']\n",
    "\n",
    "fig = ff.create_choropleth(fips = fips, values = vals,\n",
    "                           county_outline={'color': 'rgb(0,0,0)', 'width': 0.5},\n",
    "                           colorscale = colorscale, legend_title = 'Political Parties', \n",
    "                           title = 'Democratic Vs Republican Counties By FIPS COde')\n",
    "fig.layout.template = None\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#specify what we found in our best model for classification\n",
    "k = 5 \n",
    "columns = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "#jump = 1 #excluded since there is no need to specify this\n",
    "\n",
    "x4_train_scaled = X_train_scaled[:,columns]\n",
    "y4_train = Y_train['Party']\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors = k)  \n",
    "classifier.fit(x4_train_scaled, y4_train)\n",
    "\n",
    "class_dem = demographics.drop(['State','County','FIPS','Percent Rural'],axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(class_dem)\n",
    "class_dem_scaled = scaler.transform(class_dem)\n",
    "\n",
    "a = classifier.predict(class_dem_scaled)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing training and validation set\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(class_dem)\n",
    "class_dem_scaled = scaler.transform(class_dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
